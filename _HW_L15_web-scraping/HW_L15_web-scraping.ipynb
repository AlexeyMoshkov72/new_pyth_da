{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание к лекции \"Основы веб-скрапинга и работы с API\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.\n",
    "\n",
    "#### Обязательная часть\n",
    "Будем парсить страницу со свежеми новостям на habr.com/ru/all/.\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).\n",
    "\n",
    "В итоге должен формироваться датафрейм вида: <дата> - <заголовок> - <ссылка>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = ['python', 'парсинг', 'Athelas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в переменной res получаем HTML код страницы из переменной URL\n",
    "\n",
    "URL = 'https://habr.com/ru/all/'\n",
    "res = requests.get(URL)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  получаем текст HTML кода из переменной res и упорядочиваем этот текст\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем (из переменной soup) список (list) частей текста HTML кода, содержащую информацию о каждом посте\n",
    "\n",
    "posts = soup.find_all('article', class_='post')\n",
    "#posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "?map\n",
    "# a_list = list(map(lambda x: x.find('a').get('href'), articles_intro))\n",
    "\n",
    "post_class_link = list(map(lambda x: x.find('h2', class_='post__title'), posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# из каждого элемента списка (переменная posts), получаем часть HTML кода, содержащую link на полный текст статьи\n",
    "\n",
    "#post_class_link = posts[0].find('h2', class_='post__title')\n",
    "#print(post_class_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# из переменной post_class_link извлекаем ссылку на полный текст статьи (из HTML кода) \n",
    "post_link = post_class_link.find('a').get('href')\n",
    "\n",
    "\n",
    "post_link_list = list(map(lambda x: x.find('a').get('href'), post_class_link))\n",
    "#print(post_link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nГде работать в ИТ в 2020: OUTSIDE\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# из переменной post_class_link получаем заголовок статьи, как текст\n",
    "#post_class_link.text\n",
    "\n",
    "title_list = list(map(lambda x: x.text, post_class_link))\n",
    "title_list\n",
    "\n",
    "title_post = post_class_link[0].text\n",
    "title_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BeautifulSoup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ea7c795df849>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# получаем часть HTML кода по ссылке (переменная post_link)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msoup_for_full_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# soup_for_full\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BeautifulSoup' is not defined"
     ]
    }
   ],
   "source": [
    "# получаем часть HTML кода по ссылке (переменная post_link)\n",
    "soup_for_full_text = BeautifulSoup(requests.get(post_link).text, 'html.parser')\n",
    "# soup_for_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# по ссылке получаем полный текст статьи\n",
    "text = soup_for_full_text.find('div', class_='post__text').text\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYWORDS[1] in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nСегодня расскажем (и даже покажем), как обстоят дела с внутренними процессами и корпоративной жизнью в digital-агентстве OUTSIDE, ранее известном как Kodix. На наши вопросы о найме, условиях работы, команде и технологиях ответили: гендиректор Иван Пипченко, ведущий эйчар Наталия Лебедева и техлид Антон Бармин.\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем текст превью каждого поста из переменной posts\n",
    "\n",
    "text_preview = posts[0].find('div', class_='post__text').text\n",
    "text_preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'сегодня в 12:57'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_date = posts[0].find('span', class_='post__time').text\n",
    "text_date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_str_habr_date(str_date):\n",
    "    import datetime\n",
    "    \n",
    "    months = {'1':'января', '2':'февраля','3':'марта','4':'апреля','5':'мая','6':'июня','7':'июля','8':'августа','9':'сентября','10':'октября','11':'ноября','12':'декабря'}\n",
    "    date_1 = 'сегодня'\n",
    "    date_2 = 'вчера'\n",
    "    \n",
    "    if date_1 in str_date:\n",
    "        time = datetime.datetime.strptime(str_date, 'сегодня в %H:%M').time()\n",
    "        date = datetime.datetime.today().date()\n",
    "        date_post = datetime.datetime.combine(date, time)\n",
    "    elif date_2 in str_date:\n",
    "        time = datetime.datetime.strptime(str_date, 'вчера в %H:%M').time()\n",
    "        date = datetime.datetime.now().date() - datetime.timedelta(days=1) \n",
    "        date_post = datetime.datetime.combine(date, time)\n",
    "    else:\n",
    "        for key, values in months.items():\n",
    "            if values in str_date:\n",
    "                str_date = str_date.replace(values, key)\n",
    "                date_post = datetime.datetime.strptime(str_date, '%d %m %Y в %H:%M')\n",
    "    \n",
    "    return date_post\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 12, 4, 12, 57)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_str_habr_date(text_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = 'https://habr.com/ru/all/'\n",
    "res = requests.get(URL)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "posts = soup.find_all('article', class_='post')\n",
    "\n",
    "row = dict()\n",
    "habr_news = pd.DataFrame()\n",
    "\n",
    "for post in posts:\n",
    "    post_class_link = post.find('h2', class_='post__title')\n",
    "    post_link =  post_class_link.find('a').get('href')\n",
    "    title_post = post_class_link.text\n",
    "    text_preview = post.find('div', class_='post__text').text\n",
    "    text_date = post.find('span', class_='post__time').text\n",
    "    date = change_str_habr_date(text_date)\n",
    "    for word in KEYWORDS:\n",
    "        if word in title_post or word in text_preview:\n",
    "            row = {'date': date, 'link':post_link, 'title':title_post, 'preview':text_preview}\n",
    "            habr_news = pd.concat([habr_news, pd.DataFrame([row])])\n",
    "\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дополнительная часть (необязательная)\n",
    "\n",
    "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
    "\n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.\n",
    "\n",
    "Итоговый датафрейм формировать со столбцами: <дата> - <заголовок> - <ссылка> - <текст_статьи>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.\n",
    "\n",
    "#### Обязательная часть\n",
    "\n",
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck. Список email-ов задаем переменной в начале кода:\n",
    "EMAIL = [xxx@x.ru, yyy@y.com]\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <почта> - <дата утечки> - <источник утечки> - <описание утечки>\n",
    "\n",
    "Подсказка: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дополнительная часть (необязательная)\n",
    "\n",
    "Написать скрипт, который будет получать 50 последних постов указанной группы во Вконтакте.\n",
    "Документация к API VK: https://vk.com/dev/methods , вам поможет метод wall.get\n",
    "\n",
    "GROUP = 'netology'  \n",
    "TOKEN = УДАЛЯЙТЕ В ВЕРСИИ ДЛЯ ПРОВЕРКИ, НА GITHUB НЕ ВЫКЛАДЫВАТЬ\n",
    "В итоге должен формироваться датафрейм со столбцами: <дата поста> - <текст поста>\n",
    "\n",
    "#### ПРИМЕЧАНИЕ\n",
    "Домашнее задание сдается ссылкой на репозиторий GitHub. Не сможем проверить или помочь, если вы пришлете:\n",
    "\n",
    "файлы;\n",
    "архивы;\n",
    "скриншоты кода.\n",
    "Все обсуждения и консультации по выполнению домашнего задания ведутся только на соответствующем канале в slack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Как правильно задавать вопросы аспирантам, преподавателям и коллегам?\n",
    "\n",
    "Прежде чем задать вопрос необходимо попробовать найти ответ самому в интернете. Навык самостоятельного поиска информации – один из важнейших, и каждый практикующий специалист любого уровня это делает каждый день.\n",
    "\n",
    "Любой вопрос должен быть сформулирован по алгоритму:\n",
    "1) Что я делаю?\n",
    "2) Какого результата я ожидаю?\n",
    "3) Как фактический результат отличается от ожидаемого?\n",
    "4) Что я уже попробовал сделать, чтобы исправить проблему?\n",
    "\n",
    "По возможности, прикрепляйте к вопросу скриншоты, либо ссылки на код. Оставляйте только проблемный и воспроизводимый участок кода, все решение выкладывать не допускается."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
